---
title: 'Module 5: Tidyverse and working with dataframes'
author: "Jasmine Hughes"
date: "9/18/2019"
output:
  slidy_presentation: default
---

```{r chunksetup, include=FALSE}
# include any code here you don't want to show up in the document,
# e.g. package and dataset loading
library(dplyr)
library(tidyr)
library(ggplot2)
if(!('Modules' %in% unlist(strsplit(getwd(), split = '/')))) setwd('Modules')
gap <- read.csv(file.path('..', 'data', 'gapminder-FiveYearData.csv'), stringsAsFactors = FALSE)
```

# Overview

> It is often said that 80% of data analysis is spent on the process of cleaning and preparing the data. (Dasu and Johnson, 2003)

Thus before you can even get to doing any sort of sophisticated analysis or plotting, you'll generally first need to:

1. ***Manipulating*** data frames, e.g., filtering, summarizing, and conducting calculations across groups.
2. ***Tidying*** data into the appropriate format

There are two competing schools of thought within the R community.

* We should stick to the base R functions to do manipulating and tidying; `tidyverse` uses syntax that's unlike base R and is superfluous.
* We should start teaching students to manipulate data using `tidyverse` tools because they are straightfoward to use, more readable than base R, and speed up the tidying process.

I'll show you some of the `tidyverse` tools so you can make an informed decision about whether you want to use base R or these newfangled packages.

My own view: I use both base R and tidyverse, but will prefer tidyverse if I need to do more than ~3 operations on a dataset. The tidyverse is a major reason why R is so popular for data analysis, and many people that mainly working in python will sometimes switch to R just for data cleaning & graphing. 

> The tidyverse is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures. 

# Data frame Manipulation using Base R Functions

So far, you've seen the basics of manipulating data frames, e.g. subsetting, merging, and basic calculations.
For instance, we can use base R functions to calculate summary statistics across groups of observations,
e.g., the mean GDP per capita within each region:

```{r}
mean(gap[gap$continent == "Africa", "gdpPercap"])
mean(gap[gap$continent == "Americas", "gdpPercap"])
mean(gap[gap$continent == "Asia", "gdpPercap"])
```

But this isn't ideal because it involves a fair bit of repetition. Repeating yourself will cost you time, both now and later, and potentially introduce some nasty bugs (ex, from copy/pasting and forgetting to change a variable name).

# Data frame Manipulation using `dplyr`

Luckily, the [`dplyr`](https://cran.r-project.org/web/packages/dplyr/dplyr.pdf) package provides a number of very useful functions for manipulating data frames. These functions will save you time by reducing repetition. As an added bonus, you might even find the `dplyr` grammar easier to read.

Here we're going to cover 7 of the most commonly used functions as well as using pipes (`%>%`) to combine them.

1. `select()`
2. `filter()`
3. `group_by()`
4. `summarize()`
5. `mutate()`
6. `arrange()`
7. `left_join()` and relatives

If you have have not installed this package earlier, please do so now:

```{r,eval=FALSE}
# NOT run
install.packages('dplyr')
```

Now let's load the package:

```{r,message=FALSE}
library(dplyr)
```

# `dplyr::select`

Imagine that we just received the gapminder dataset, but are only interested in a few variables in it. We could use the `select()` function to keep only the columns corresponding to variables we select.

```{r}
year_country_gdp_dplyr <- select(gap, year, country, gdpPercap)
head(year_country_gdp_dplyr)
```
![](img/dplyr-fig1.png)


If we open up `year_country_gdp`, we'll see that it only contains the year, country and gdpPercap. This is equivalent to the base R subsetting function:

```{r}
year_country_gdp_base <- gap[,c("year", "country", "gdpPercap")]
head(year_country_gdp_base)
```

We can even check that these two data frames are equivalent:

```{r}
# checking equivalence: TRUE indicates an exact match between these objects
all.equal(year_country_gdp_dplyr, year_country_gdp_base)
```

But, as we will see, `dplyr` makes for much more readable, efficient code because of its *pipe* operator.

# piping with `dplyr`

![](img/magrittr_hex.png)

Above, we used what's called "normal" grammar, but the strengths of `dplyr` lie in combining several functions using *pipes*.

Pipes take the input on the left side of the `%>%` symbol and pass it in as the first argument to the function on the right side.

coffee beans %>% harvest() %>% roast() %>% grind() %>% add("hot water") %>% filter() %>% drink().

Since the pipe grammar is unlike anything we've seen in R before, let's repeat what we've done above using pipes.

```{r}
year_country_gdp <- gap %>% select(year, country, gdpPercap)
```

First we summon the gapminder dataframe and pass it on to the next step using the pipe symbol `%>%`
The second steps is the `select()` function.

In this case we don't specify which data object we use in the call to `select()` since we've piped it in.

**Fun Fact**: There is a good chance you have encountered pipes before in the shell. In R, a pipe symbol is `%>%` while in the shell it is `|.` But the concept is the same!

All tidyverse functions take `.data` as their first argument. You can either supply your "input" dataframe as the `.data` argument, or pipe it in. The following two operations are identical:

```{r data_argument_in_pipes}
identical(gap %>% select(year, country, gdpPercap),
          select(gap, year, country, gdpPercap))

```

# `dplyr::filter`

Now let's say we're only interested in African countries. We can combine `select` and `filter` to select only the observations where `continent` is `Africa`.

```{r}
year_country_gdp_africa <- gap %>%
    filter(continent == "Africa") %>%
    select(year,country,gdpPercap)
```

As with last time, first we pass the gapminder data frame to the `filter()` function, then we pass the filtered version of the gapminder data frame to the `select()` function.

To clarify, both the `select` and `filter` functions subsets the data frame. The difference is that `select` extracts certain *columns*, while `filter` extracts certain *rows*.

**Note:** The order of operations is very important in this case. If we used 'select' first, filter would not be able to find the variable `continent` since we would have removed it in the previous step.

# `dplyr` Calculations Across Groups

A common task you'll encounter when working with data is running calculations on different groups within the data. For instance, what if we wanted to calculate the mean GDP per capita for each continent?

In base R, you would have to run the `mean()` function for each subset of data:

```{r}
mean(gap$gdpPercap[gap$continent == "Africa"])
mean(gap$gdpPercap[gap$continent == "Americas"])
mean(gap$gdpPercap[gap$continent == "Asia"])
mean(gap$gdpPercap[gap$continent == "Europe"])
mean(gap$gdpPercap[gap$continent == "Oceania"])
```

That's a lot of repetition! To make matters worse, what if we wanted to add these values to our original data frame as a new column? We would have to write something like this:

```{r}
gap$mean.continent.GDP <- NA

gap$mean.continent.GDP[gap$continent == "Africa"] <- mean(gap$gdpPercap[gap$continent == "Africa"])

gap$mean.continent.GDP[gap$continent == "Americas"] <- mean(gap$gdpPercap[gap$continent == "Americas"])

gap$mean.continent.GDP[gap$continent == "Asia"] <- mean(gap$gdpPercap[gap$continent == "Asia"])

gap$mean.continent.GDP[gap$continent == "Europe"] <- mean(gap$gdpPercap[gap$continent == "Europe"])

gap$mean.continent.GDP[gap$continent == "Oceania"] <- mean(gap$gdpPercap[gap$continent == "Oceania"])
```

You can see how this can get pretty tedious, especially if we want to calculate more complicated or refined statistics. We could use loops or apply functions, but these can be difficult, slow, or error-prone.

# `dplyr` split-apply-combine

The abstract problem we're encountering here is know as "split-apply-combine":

![](img/splitapply.png)

We want to *split* our data into groups (in this case continents), *apply* some calculations on each group, then  *combine* the results together afterwards.


Luckily, `dplyr` offers a much cleaner, straight-forward solution to this problem.

```{r}
# remove this column -- there are two easy ways!
gap <- gap %>% select(-mean.continent.GDP)
# OR
gap$mean.continent.GDP <- NULL
```

# `dplyr::group_by`

We've already seen how `filter()` can help us select observations that meet certain criteria (in the above: `continent == "Europe"`). More helpful, however, is the `group_by()` function, which will essentially use every unique criteria that we could have used in `filter()`.

A `grouped_df` can be thought of as a `list` where each item in the `list` is a `data.frame` which contains only the rows that correspond to the a particular value `continent` (at least in the example above).

![](img/dplyr-fig2.png)

# `dplyr::summarize`

`group_by()` on its own is not particularly interesting.
It's much more exciting used in conjunction with the `summarize()` function.
This will allow use to create new variable(s) by applying transformations to variables in each of the continent-specific data frames.
In other words, using the `group_by()` function, we split our original data frame into multiple pieces, which we then apply summary functions to (e.g. `mean()` or `sd()`) within `summarize()`.
The output is a new data frame reduced in size, with one row per group.

```{r}
gdp_bycontinents <- gap %>%
    group_by(continent) %>%
    summarize(mean_gdpPercap = mean(gdpPercap))
head(gdp_bycontinents)
```

![](img/dplyr-fig3.png)

That allowed us to calculate the mean gdpPercap for each continent. But it gets even better -- the function `group_by()` allows us to group by multiple variables. Let's group by `year` and `continent`.

```{r}
gdp_bycontinents_byyear <- gap %>%
    group_by(continent, year) %>%
    summarize(mean_gdpPercap = mean(gdpPercap))
head(gdp_bycontinents_byyear)
```

That is already quite powerful, but it gets even better! You're not limited to defining 1 new variable in `summarize()`.

```{r}
gdp_pop_bycontinents_byyear <- gap %>%
    group_by(continent, year) %>%
    summarize(mean_gdpPercap = mean(gdpPercap),
              sd_gdpPercap = sd(gdpPercap),
              mean_pop = mean(pop),
              sd_pop = sd(pop))
head(gdp_pop_bycontinents_byyear)
```

# `dplyr::mutate`

What if we wanted to add these values to our original data frame instead of creating a new object? For this, we can use the `mutate()` function, which is similar to `summarize()` except it creates new variables in the same data frame that you pass into it.

```{r}
gap_with_extra_vars <- gap %>%
    group_by(continent, year) %>%
    mutate(mean_gdpPercap = mean(gdpPercap),
              sd_gdpPercap = sd(gdpPercap),
              mean_pop = mean(pop),
              sd_pop = sd(pop))
head(gap_with_extra_vars)
```

We can use also use `mutate()` to create new variables prior to (or even after) summarizing information. Note that `mutate()` does not need to operate on grouped data and it can do element-wise transformations.

```{r}
gdp_pop_bycontinents_byyear <- gap %>%
    mutate(gdp_billion = gdpPercap*pop/10^9) %>%
    group_by(continent, year) %>%
    summarize(mean_gdpPercap = mean(gdpPercap),
              sd_gdpPercap = sd(gdpPercap),
              mean_pop = mean(pop),
              sd_pop = sd(pop),
              mean_gdp_billion = mean(gdp_billion),
              sd_gdp_billion = sd(gdp_billion))
head(gdp_pop_bycontinents_byyear)
```

# `mutate` vs. `summarize`

It can be confusing to decide whether to use `mutate` or `summarize`. The key distinction is whether you want the output to have one row for each group or one row for each row in the original data frame:

  - `mutate`: creates new columns with as many rows as the original data frame
  - `summarize`: creates a dataframe with as many rows as groups

Note that if you use an aggregation function such as `mean()` within `mutate()` without using `groupby()`, you'll simply do the summary over all the rows of the input dataframe.

And if you use an aggregation function such as `mean()` within `summarize()` without using `group_by()`, you'll simply create an output dataframe with one row (i.e., the whole input dataframe is a single group).

# `dplyr::arrange`

Let's say we want to sort the rows in our data frame according to values in a certain column. We can use the `arrange()` function to do this. For instance, let's organize our rows by `year` (recent first), and then by `continent`.

```{r}
gap_with_extra_vars <- gap %>%
    group_by(continent, year) %>%
    mutate(mean_gdpPercap = mean(gdpPercap),
              sd_gdpPercap = sd(gdpPercap),
              mean_pop = mean(pop),
              sd_pop = sd(pop)) %>%
    arrange(desc(year), continent)
head(gap_with_extra_vars)
```

# `dplyr::left_join()`

Sometimes we need to use data available from multiple sources. To take advantage of the functions we saw above, we need data points of interest to be in the same dataframe. The join family of functions helps here.

```{r joining}
pt_char <- data.frame(pt = c("M.H.", "P.J.", "K.G.", "A.C."),
                      age = c(77, 35, 56, 48),
                      weight = c(65, 82, 70, 100),
                      stringsAsFactors = F)
pt_doses <- data.frame(pt = c("M.H.", "P.J.", "K.G.", "M.H.", "S.C."),
                       mg_per_kg = c(15, 15, 10, 20, 15),
                       interval = c("Q8", "Q12", "Q6", "Q8", "Q8"),
                       stringsAsFactors = F)

# left_join adds all the data from the second df to the matching rows of the left dataframe
left_join(pt_char, pt_doses)
```
Note what happens to patient A.C., who does not have dosing information, and patient S.C., for whom we do not have patient characteristics. Also, see how R handled patient M.H., who was in the dosing table twice. Let's try the reverse:

```{r joining2}
pt_doses %>% left_join(pt_char, by = "pt")

# R will do its best guess to try judge which columns you want to join on if you do not otherwise specify
# Here, the names match, but not all data is so convenient. Here's a contrived example:
pt_doses %>%
  rename(patient = pt) %>%
  left_join(pt_char, by = c("patient" = "pt"))
```
What happened here to A.C., M.H. and S.C.?

```{r joining3}
# Right join is the reverse of left_join
right_join(pt_char, pt_doses)

```
What if we want to keep all entries?

```{r joining4}
full_join(pt_char, pt_doses)
```
What if we want to keep only patients for whom we have complete information?

```{r joining5}
inner_join(pt_char, pt_doses) %>%
  mutate(mg = mg_per_kg * weight)
```

# `dplyr` Take-aways

* Human readable: the function names describe the action being done
* Piping: chain functions in a step-by-step way, rather than nesting

```{r}
# without pipes:
gap_with_extra_vars <- arrange(
    mutate(
      group_by(gap, continent, year),
      mean_gdpPercap = mean(gdpPercap)
      ),
    desc(year), continent)
```
* Facilitates split-apply-combine manipulations

# Tidying Data

Even before we conduct analysis or calculations, we need to put our data into the correct format. The goal here is to rearrange a messy dataset into one that is **tidy**

The two most important properties of tidy data are:

1) Each column is a variable.
2) Each row is an observation.

Tidy data is easier to work with, because you have a consistent way of referring to variables (as column names) and observations (as row indices). It then becomes easy to manipulate, visualize, and model.

For more on the concept of *tidy* data, read Hadley Wickham's paper [here](http://vita.had.co.nz/papers/tidy-data.html)

# Tidying Data/Wide vs. Long Formats

> "Tidy datasets are all alike but every messy dataset is messy in its own way." – Hadley Wickham

Tabular datasets can be arranged in many ways. For instance, consider the data below. Each data set displays information on heart rate observed in individuals across 3 different time periods. But the data are organized differently in each table.

```{r}
wide <- data.frame(
  name = c("Wilbur", "Petunia", "Gregory"),
  time1 = c(67, 80, 64),
  time2 = c(56, 90, 50),
  time3 = c(70, 67, 101)
)
wide

long <- data.frame(
  name = c("Wilbur", "Petunia", "Gregory", "Wilbur", "Petunia", "Gregory", "Wilbur", "Petunia", "Gregory"),
  time = c(1, 1, 1, 2, 2, 2, 3, 3, 3),
  heartrate = c(67, 80, 64, 56, 90, 50, 70, 67, 10)
)
long
```

**Question**: Which one of these do you think is the *tidy* format?

**Answer**: The first dataframe (the "wide" one) would not be considered *tidy* because values (i.e., heartrate) are spread across multiple columns.

We often refer to these different structurs as "long" vs. "wide" formats. In the "long" format, you usually have 1 column for the observed variable and the other columns are ID variables.

For the "wide" format each row is often a site/subject/patient and you have multiple observation variables containing the same type of data. These can be either repeated observations over time, or observation of multiple variables (or a mix of both). In the above case, we had the same kind of data (heart rate) entered across 3 different columns, corresponding to three different time periods.

![](img/tidyr-fig1.png)

You may find data input may be simpler and some programs/functions may prefer the "wide" format. However, many of R’s functions have been designed assuming you have "long" format data.

# Tidying the Gapminder Data

Lets look at the structure of our original gapminder dataframe:

```{r}
head(gap)
```

**Question**: Is this data frame **wide** or **long**?

**Answer**: This data frame is somewhere in between the purely 'long' and 'wide' formats. We have 3 "ID variables" (`continent`, `country`, `year`) and 3 "Observation variables" (`pop`, `lifeExp`, `gdpPercap`).

Despite not having ALL observations in 1 column, this intermediate format makes sense given that all 3 observation variables have different units. As we have seen, many of the functions in R are often vector based, and you usually do not want to do mathematical operations on values with different units.

On the other hand, there are some instances in which a purely long or wide format is ideal (e.g. plotting). Likewise, sometimes you'll get data on your desk that is poorly organized, and you'll need to **reshape** it.

# `tidyr`

Thankfully, the `tidyr` package will help you efficiently transform your data regardless of original format.

```{r}
# Install the "tidyr" package (only necessary one time)
# install.packages("tidyr") # Not Run

# Load the "tidyr" package (necessary every new R session)
library(tidyr)
```

# `tidyr::gather`

Until now, we've been using the nicely formatted original gapminder data set. This data set is not quite wide and not quite long -- it's something in the middle, but "real" data (i.e., our own research data) will never be so well organized. Here let's start with the wide format version of the gapminder data set.

```{r}
gap_wide <- read.csv("../Data/gapminder_wide.csv", stringsAsFactors = FALSE)
head(gap_wide)
```

The first step towards getting our nice intermediate data format is to first convert from the wide to the long format.
The function `gather()` will 'gather' the observation variables into a single variable. This is sometimes called "melting" your data, because it melts the table from wide to long. Those data will be melted into two variables: one for the variable names, and the other for the variable values.

```{r}
gap_long <- gap_wide %>%
    gather(obstype_year, obs_values, 3:38)
head(gap_long)
```

Notice that we put 3 arguments into the `gather()` function:

1. the name the new column for the new ID variable (`obstype_year`),
2. the name for the new amalgamated observation variable (`obs_value`),
3. the indices of the old variables (`3:38`, signalling columns 3 through 38) that we want to gather into one variable. Notice that we don't want to melt down columns 1 and 2, as these are considered "ID" variables.

# `tidyr::select`

If there are a lot of columns or they're named in a consistent pattern, we might not want to select them using the column numbers.
It'd be easier to use some information contained in the names themselves.
We can select variables using:

* variable indices
* variable names (without quotes)
* `x:z` to select all variables between x and z
* `-y` to *exclude* y
* `starts_with(x, ignore.case = TRUE)`: all names that starts with `x`
* `ends_with(x, ignore.case = TRUE)`: all names that ends with `x`
* `contains(x, ignore.case = TRUE)`: all names that contain `x`

See the `select()` function in `dplyr` for more options.

For instance, here we do the same gather operation with (1) the `starts_with` function, and (2) the `-` operator:

```{r}
# with the starts_with() function
gap_long <- gap_wide %>%
    gather(obstype_year, obs_values, starts_with('pop'),
           starts_with('lifeExp'), starts_with('gdpPercap'))
head(gap_long)

# with the - operator
gap_long <- gap_wide %>%
  gather(obstype_year, obs_values, -continent, -country)
head(gap_long)
```

However you choose to do it, notice that the output collapses all of the measure variables into two columns: one containing new ID variable, the other containing the observation value for that row.

# `tidyr::separate`

You'll notice that in our long dataset, `obstype_year` actually contains 2 pieces of information, the observation type (`pop`, `lifeExp`, or `gdpPercap`) and the `year`.

We can use the `separate()` function to split the character strings into multiple variables:

```{r}
gap_long_sep <- gap_long %>%
  separate(obstype_year, into = c('obs_type','year'), sep = "_") %>%
  mutate(year = as.integer(year))
head(gap_long_sep)
```

If you didn't use `tidyr` to do this, you'd have to use the `strsplit` function and use multiple lines of code to replace the column in `gap_long` with two new columns. This solution is much cleaner.

# `tidyr::spread`

The opposite of `gather()` is `spread()`. It spreads our observation variables back out to make a wider table. We can use this function to spread our `gap_long()` to the original "medium" format.

```{r}
gap_medium <- gap_long_sep %>%
  spread(obs_type, obs_values)
head(gap_medium)
```

All we need is some quick fixes to make this dataset identical to the original `gap` dataset:

```{r}
gap <- read.csv("../data/gapminder-FiveYearData.csv")
head(gap_medium)
head(gap)

# rearrange columns
gap_medium <- gap_medium[,names(gap)]
head(gap_medium)

# arrange by country, continent, and year
gap_medium <- gap_medium %>%
  arrange(country,continent,year)
head(gap_medium)
```

# Extra Resources

`dplyr` and `tidyr` have many more functions to help you wrangle and manipulate your data. See the  [Data Wrangling Cheat Sheet](https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf) for more.

There are some other useful packages in the [tidyverse](http://www.tidyverse.org):

* `ggplot2` for plotting (I'll cover this in module 8)
* `readr` and `haven` for reading in data with structure other than csv
* `stringr`, `lubridate`, `forcats` for manipulating strings, dates, and factors, respectively
* many more!

# Breakout

### `dplyr`

1. Use `dplyr` to create a data frame containing the median `lifeExp` for each continent

2. Use `dplyr` to add a column to the gapminder dataset that contains the total population of the continent of each observation in a given year. For example, if the first observation is Afghanistan in 1952, the new column would contain the population of Asia in 1952.

3. Use `dplyr` to add a column called `gdpPercap_diff` that contains the difference between the observation's `gdpPercap` and the mean `gdpPercap` of the continent in that year. Arrange the dataframe by the column you just created, in descending order (so that the relatively richest country/years are listed first)

### `tidyr`

4. Subset the results from question #3 to select only the `country`, `year`, and `gdpPercap_diff` columns. Use tidyr put it in wide format so that countries are rows and years are columns.

Hint: you'll probably see a message about a missing grouping variable. If you don't want continent included, you can pass the output of problem 3 through `ungroup()` to get rid of the continent information.


# Next steps in `dplyr`
These functions will cover the large majority of data operations you will likely need to perform. But here are a few of my other favorite functions that I'd like to cover just in case you need them.

## `case_when()`
Case when should be used if you ever find yourself needing to next two or more `ifelse` functions. Compare the readability of the two examples below:

```{r case_when}
wbc_counts <- data.frame(
  pt = c("M.H.", "P.J.", "K.G.", "A.C.", "D.S.", "H.R."),
  lab = c(300, 4000, 2100, 1100, 800, 550)
)

# case_when
wbc_counts %>%
  mutate(assessment = case_when(
    lab < 500     ~ "Severe neutropenia",
    lab < 1000    ~ "Moderate neutropenia",
    lab < 1500    ~ "Mild neutropenia",
    TRUE          ~ "Normal"
  ))

# nested if_else
wbc_counts %>%
  mutate(assessment = ifelse(lab < 500, "Severe neutropenia",
                             ifelse(lab < 1000, "Moderate neutropenia",
                                    ifelse(lab < 1500, "Mild neutropenia",
                                           "Normal"))))


```

# Operating on multiple columns as a time

The functions we've seen previously also have variants that allow you to operate on multiple columns, either by naming them specifically or using a logical condition.

Here's an example of code I might use if I need to make a table formatted nicely for output.

```{r mutate_at}
gap %>%
  mutate_if(is.numeric, ~round(.))

```
There's also `mutate_all` for performing the same operation on all columns (in place), and `mutate_at`, which allows you to perform the same operation at a selection of columns.

Other `dplyr` functions have similar variants: `filter_at`, `filter_if`, `filter_all`, `select_if`, etc...

```{r select_at}
gap %>%
  mutate(gdpTot = gdpPercap * pop) %>%
  select_at(vars(country, starts_with('gdp')))

# This example is fairly simple, but you can see how it would be convenient if you had many columns with a very similar name structure.
```
To help _generically_ refer to column names, there are a bunch of select helper functions that can make your code faster to write and more robust. See `?select_helpers` for more.

# Window functions

Window functions perform operation over some particular "window" or subset of a dataframe in a way that is slightly different to group_by. Operations apply to each row, instead of equally to every member of a group. The most common ones you may run into are `lag` and its opposite, `lead`, which allow you to perform operations on the last/next row in the dataset.

```{r lag}
gap %>%
  group_by(country) %>%
  mutate(pop_growth = (pop - lag(pop, order_by = year)) / 
           lag(pop, order_by = year)) %>%
  ungroup() %>%
  arrange(desc(pop_growth))
  

```

# `distinct()`

Sometimes data has unwanted duplicates. `distinct` is the dataframe version of `unique` (which works on vectors).

```{r distinct}
raw_lab_data <- data.frame(
  pt = c("M.H.", "P.J.", "K.G.", "A.C.", "D.S.", "H.R.", "M.H.", "H.R."),
  lab = c(300, 4000, 2100, 1100, 800, 550, 300, 550)
)
  
raw_lab_data %>% 
  distinct()
```

# Working with row numbers
The functions `row_number()` and `n()` are convenient for when knowing the number of rows in a grouping is important. 

For example, if you wanted to look only at patients with more than 1 lab:

```{r n_filter}
repeat_lab_data <- data.frame(
  pt = c("M.H.", "P.J.", "K.G.", "A.C.", "D.S.", "H.R.", "M.H.", "H.R.", "D.S.", "M.H."),
  lab = c(300, 4000, 2100, 1100, 800, 550, 400, 650, 700, 400)
)

repeat_lab_data %>%
  group_by(pt) %>%
  filter(n() > 1) %>% 
  ungroup()

```

Or if you want to label the observation number:

```{r row_number}
repeat_lab_data %>%
  group_by(pt) %>% 
  mutate(obs_number = row_number()) %>%
  ungroup()
  
```

# Joining similar datasets vertically

We previously saw `left_join()` and its related functions for when you have overlapping information in two dataframes and you want to combine them, adding new columns. What if you have two very similar data frames and you wish to add them vertically instead?

```{r bindrows}
df_a <- data.frame(pt = c("M.H.", "P.J.", "K.G.", "A.C."),
                   wbc = c(300, 4000, 2100, 1100),
                   stringsAsFactors = F)
df_b <- data.frame(pt = c("S.L.", "P.K.", "K.S.", "A.L."),
                   wbc = c(1800, 2000, 780, 1100), 
                   stringsAsFactors = F)
df_c <- data.frame(pt = c("S.L.", "P.K.", "K.S.", "A.L."),
                   bilirubin = c(1.1, 0.8, 1.7, 2.1),
                   wbc = c(1800, 2000, 780, 1100), 
                   stringsAsFactors = F)

# In base R
rbind(df_a, df_b)

# In tidyverse
bind_rows(df_a, df_b)

# What happens here?
bind_rows(df_a, df_c)
# rbind(df_a, df_c)

# What happens here?
bind_rows(df_a, df_c[c(1:2)])
#rbind(df_a, df_c[c(1:2)])

```

Remember that dynamically growing a data frame in a loop is slow, and should be avoided where possible.

Both `rbind()` and `bind_rows()` have column versions: `cbind()` and `bind_cols()`

# `slice()`
Sometimes you want to limit your analysis to particular rows, but the exact expression you want to apply to select those rows doesn't fit nicely into a `filter()` expression. In those scenarios, consider if `slice()` might help. For example, what if we wanted to look at what year each country achieved its maximum life expectancy in the gapminder dataset?

```{r slice}

max_le <- gap %>%
  group_by(country) %>%
  slice(which.max(lifeExp)) %>%
  select(country, continent, year, lifeExp) %>%
  arrange(year)

head(max_le)

```
`slice()` takes an index/integer row value (1, 4, etc..). The base R function `which.max()` returns the index of the lowest value. Since we've grouped by country, `which.max()` (contrast with `which.min()`) returns the index of the minimum value of the specified column.

```{r slice_with_index}
# You can also enter integer values directly
max_le2 <- gap %>%
  group_by(country) %>%
  arrange(desc(lifeExp)) %>%
  slice(1) %>%
  select(country, continent, year, lifeExp) %>%
  arrange(year)

identical(max_le, max_le2)

```